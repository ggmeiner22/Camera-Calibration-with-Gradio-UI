{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMQc+qLt0wwNmSXZCdqId2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggmeiner22/Camera-Calibration-with-Gradio-UI/blob/main/Camera_Calibration_with_Gradio_UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Camera Calibration (OpenCV + Gradio UI)\n",
        "## In this project, I will calibrate my own camera using OpenCV’s calibration tools.\n",
        "\n",
        "### The goal is to compute my camera’s intrinsic parameters (focal length, principal point, distortion coefficients).\n",
        "\n",
        "### I will also build a small Gradio user interface (UI) to streamline the calibration process, visualize results, and demonstrate understanding of camera geometry.\n",
        "\n"
      ],
      "metadata": {
        "id": "fhcGXGypQCfQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "by8pAQZCN6lh"
      },
      "outputs": [],
      "source": [
        "%pip -q install opencv-python-headless numpy gradio plotly pytransform3d==3.3.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add imports:"
      ],
      "metadata": {
        "id": "mfkQfde-RIUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard library imports\n",
        "import os, json, glob, io, base64, math, textwrap, random\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict, Any\n",
        "\n",
        "# Third-party / scientific stack\n",
        "import numpy as np\n",
        "import cv2 as cv                          # OpenCV; aliased as 'cv' by convention\n",
        "import gradio as gr                       # Gradio UI components for Colab apps\n",
        "import plotly.graph_objects as go         # Interactive plotting (3D/2D)\n",
        "from pytransform3d.transformations import plot_transform  # 3D frame viz helper\n",
        "from PIL import Image                     # Pillow for image I/O/format conversions\n",
        "import uuid, time                         # UUIDs for unique filenames; timing utilities\n",
        "import base64, io                         # (Duplicate of earlier base64, io; harmless but redundant)\n",
        "\n",
        "# --- Paths & filesystem setup (Colab-friendly) ---\n",
        "# Use a stable base directory in Colab's ephemeral filesystem.\n",
        "BASE_DIR = \"/content\"\n",
        "\n",
        "# Directory to store uploaded or generated images.\n",
        "IMG_DIR  = os.path.join(BASE_DIR, \"images\")\n",
        "\n",
        "# Create the image directory if it doesn't already exist.\n",
        "os.makedirs(IMG_DIR, exist_ok=True)\n",
        "\n",
        "# --- Randomness / reproducibility ---\n",
        "# Deterministic NumPy random number generator for reproducible behavior across runs.\n",
        "# Prefer NumPy's Generator over np.random for better APIs and stateless functions.\n",
        "RNG = np.random.default_rng(42)\n"
      ],
      "metadata": {
        "id": "JKH3KHvRRB9E"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Collect Calibration Images"
      ],
      "metadata": {
        "id": "dcv89lFaXtf2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the image into /content/pattern.png"
      ],
      "metadata": {
        "id": "UE-kFogYUIFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Download the OpenCV checkerboard pattern for calibration ---\n",
        "import urllib.request\n",
        "\n",
        "# Publicly hosted checkerboard pattern from OpenCV documentation\n",
        "url = \"https://docs.opencv.org/4.x/pattern.png\"\n",
        "\n",
        "# Save location in Colab filesystem\n",
        "save_path = \"/content/pattern.png\"\n",
        "\n",
        "# Download the file from URL and save locally\n",
        "urllib.request.urlretrieve(url, save_path)\n",
        "\n",
        "# Confirm to the user that the file was saved\n",
        "print(f\"Saved checkerboard to {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puWQINZ-TqU_",
        "outputId": "00e758cd-cea6-40bf-9b64-55488dd233bc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved checkerboard to /content/pattern.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the OpenCV chessboard calibration pattern: pattern.png."
      ],
      "metadata": {
        "id": "J7ijfKiJUYgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Display the downloaded checkerboard image inside the Colab notebook ---\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Use IPython's display utilities to show the image inline.\n",
        "# `filename=save_path` points to the chessboard pattern we just saved.\n",
        "display(Image(filename=save_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7PKC3SICUYGn",
        "outputId": "6b62f043-b38f-4781-b1e2-c0cebff0889d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I/O class"
      ],
      "metadata": {
        "id": "0qcT6DlQV3Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IO:\n",
        "    \"\"\"\n",
        "    Utility class for common file and image I/O operations.\n",
        "\n",
        "    Provides static helper methods to handle:\n",
        "    - Directory creation\n",
        "    - Image listing\n",
        "    - JSON read/write\n",
        "    - Image read/write with automatic BGR↔RGB conversion\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def ensure_dir(path: str):\n",
        "        \"\"\"Ensure that a directory exists (create if missing).\"\"\"\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def list_images(folder: str, exts=(\".jpg\", \".jpeg\", \".png\", \".bmp\")) -> List[str]:\n",
        "        \"\"\"\n",
        "        Return a sorted list of image file paths in a folder.\n",
        "\n",
        "        Args:\n",
        "            folder: Directory to search.\n",
        "            exts: Tuple of file extensions to include.\n",
        "\n",
        "        Returns:\n",
        "            List of matching image paths.\n",
        "        \"\"\"\n",
        "        files = []\n",
        "        for e in exts:\n",
        "            files.extend(glob.glob(os.path.join(folder, f\"*{e}\")))\n",
        "        return sorted(files)\n",
        "\n",
        "    @staticmethod\n",
        "    def save_json(obj: Dict[str, Any], path: str):\n",
        "        \"\"\"\n",
        "        Save a Python dictionary as a JSON file with indentation.\n",
        "\n",
        "        Args:\n",
        "            obj: Serializable dictionary.\n",
        "            path: Output file path.\n",
        "        \"\"\"\n",
        "        with open(path, \"w\") as f:\n",
        "            json.dump(obj, f, indent=2)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_json(path: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Load and return a JSON file as a Python dictionary.\n",
        "\n",
        "        Args:\n",
        "            path: Path to .json file.\n",
        "\n",
        "        Returns:\n",
        "            Parsed dictionary.\n",
        "        \"\"\"\n",
        "        with open(path, \"r\") as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    @staticmethod\n",
        "    def imread_rgb(path: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Read an image as an RGB NumPy array (OpenCV loads as BGR by default).\n",
        "\n",
        "        Args:\n",
        "            path: Path to image file.\n",
        "\n",
        "        Returns:\n",
        "            Image array in RGB format (H, W, 3).\n",
        "\n",
        "        Raises:\n",
        "            FileNotFoundError: If the image path is invalid or unreadable.\n",
        "        \"\"\"\n",
        "        bgr = cv.imread(path, cv.IMREAD_COLOR)\n",
        "        if bgr is None:\n",
        "            raise FileNotFoundError(path)\n",
        "        return cv.cvtColor(bgr, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    @staticmethod\n",
        "    def imwrite_rgb(path: str, rgb: np.ndarray):\n",
        "        \"\"\"\n",
        "        Write an RGB NumPy array to disk (convert to BGR before saving).\n",
        "\n",
        "        Args:\n",
        "            path: Output file path.\n",
        "            rgb: Image array in RGB format (H, W, 3).\n",
        "        \"\"\"\n",
        "        bgr = cv.cvtColor(rgb, cv.COLOR_RGB2BGR)\n",
        "        cv.imwrite(path, bgr)\n"
      ],
      "metadata": {
        "id": "C8C4eXShV7fP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Board class"
      ],
      "metadata": {
        "id": "Tw6j4St4bs_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Board:\n",
        "    \"\"\"\n",
        "    Chessboard model for camera calibration.\n",
        "\n",
        "    Note:\n",
        "        - `pattern_size` refers to the **number of inner corners**\n",
        "          (e.g., a 9x6 board has 9×6 inner corners, not squares).\n",
        "        - Units of the generated object points are determined\n",
        "          by `square_size_m`.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def object_points(pattern_size: Tuple[int, int], square_size_m: float) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Generate the 3D world coordinates of chessboard corners.\n",
        "\n",
        "        Args:\n",
        "            pattern_size: (cols, rows) = number of inner corners per row/column.\n",
        "            square_size_m: Size of one square's side in meters (or chosen unit).\n",
        "\n",
        "        Returns:\n",
        "            objp: (N, 3) NumPy array of corner coordinates in 3D space,\n",
        "                  with Z=0 (flat board). Shape = (rows*cols, 3), dtype=float32.\n",
        "        \"\"\"\n",
        "        cols, rows = pattern_size\n",
        "        objp = np.zeros((rows * cols, 3), np.float32)\n",
        "\n",
        "        # Generate grid of x,y coordinates for corners\n",
        "        xs, ys = np.meshgrid(np.arange(cols), np.arange(rows))\n",
        "\n",
        "        # Fill in X and Y; multiply by square size to convert to real-world units\n",
        "        objp[:, :2] = np.vstack([xs.ravel(), ys.ravel()]).T * square_size_m\n",
        "\n",
        "        # Z stays 0 → flat plane\n",
        "        return objp\n",
        "\n",
        "    @staticmethod\n",
        "    def pattern_tuple(cols: int, rows: int) -> Tuple[int, int]:\n",
        "        \"\"\"\n",
        "        Convenience method to return (cols, rows) as a tuple.\n",
        "\n",
        "        Args:\n",
        "            cols: Number of inner corners per row.\n",
        "            rows: Number of inner corners per column.\n",
        "\n",
        "        Returns:\n",
        "            Tuple (cols, rows)\n",
        "        \"\"\"\n",
        "        return (cols, rows)\n"
      ],
      "metadata": {
        "id": "oRIVMmeHbvOW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image class"
      ],
      "metadata": {
        "id": "g8uH32_5bv2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Img:\n",
        "    \"\"\"\n",
        "    Image drawing utilities for visualization of calibration results.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def draw_axes(\n",
        "        rgb: np.ndarray,\n",
        "        K: np.ndarray,\n",
        "        D: np.ndarray,\n",
        "        rvec: np.ndarray,\n",
        "        tvec: np.ndarray,\n",
        "        axis_len: float\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Draw 3D coordinate axes (X, Y, Z) on an RGB image given camera pose.\n",
        "\n",
        "        Args:\n",
        "            rgb: Input image in RGB format, shape (H, W, 3), dtype=uint8.\n",
        "            K: Camera intrinsic matrix (3x3).\n",
        "            D: Distortion coefficients (OpenCV convention).\n",
        "            rvec: Rotation vector (Rodrigues form, 3x1).\n",
        "            tvec: Translation vector (3x1).\n",
        "            axis_len: Length of the axis lines in world units.\n",
        "\n",
        "        Returns:\n",
        "            Copy of the input image with axes drawn:\n",
        "                - X axis = red\n",
        "                - Y axis = green\n",
        "                - Z axis = blue\n",
        "        \"\"\"\n",
        "        img = rgb.copy()\n",
        "\n",
        "        # Define axis endpoints in 3D (origin + X, Y, Z directions)\n",
        "        axis_3d = np.float32([\n",
        "            [0, 0, 0],                  # origin\n",
        "            [axis_len, 0, 0],           # X-axis\n",
        "            [0, axis_len, 0],           # Y-axis\n",
        "            [0, 0, axis_len]            # Z-axis points OUT of the board (toward camera by our visual convention)\n",
        "        ])\n",
        "\n",
        "        # Project 3D points into 2D image space\n",
        "        axis_2d, _ = cv.projectPoints(axis_3d, rvec, tvec, K, D)\n",
        "        axis_2d = axis_2d.reshape(-1, 2).astype(int)\n",
        "\n",
        "        # Unpack into named points\n",
        "        o, x, y, z = map(tuple, axis_2d)\n",
        "\n",
        "        # Draw lines for each axis in distinct colors\n",
        "        cv.line(img, o, x, (255, 0, 0), 3)    # X axis → red\n",
        "        cv.line(img, o, y, (0, 255, 0), 3)    # Y axis → green\n",
        "        cv.line(img, o, z, (0, 0, 255), 3)    # Z axis → blue\n",
        "\n",
        "        return img\n",
        "\n",
        "    @staticmethod\n",
        "    def put_text(img: np.ndarray, text: str, org=(10, 30)):\n",
        "        \"\"\"\n",
        "        Overlay text on an image (RGB), with a yellow font for visibility.\n",
        "\n",
        "        Args:\n",
        "            img: Input image (RGB).\n",
        "            text: String to draw.\n",
        "            org: Bottom-left corner of the text string in pixels.\n",
        "\n",
        "        Returns:\n",
        "            Copy of the input image with text overlay.\n",
        "        \"\"\"\n",
        "        out = img.copy()\n",
        "        cv.putText(\n",
        "            out,\n",
        "            text,\n",
        "            org,\n",
        "            cv.FONT_HERSHEY_SIMPLEX,\n",
        "            1.0,              # font scale\n",
        "            (255, 255, 0),    # yellow text (BGR)\n",
        "            2,                # thickness\n",
        "            cv.LINE_AA        # anti-aliased text\n",
        "        )\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "F1BffUSybweH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Camera class"
      ],
      "metadata": {
        "id": "0ubDMn2Xb1VA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Cam:\n",
        "    \"\"\"\n",
        "    Camera-related utilities for calibration and pose handling.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def rodrigues_to_R(rvec: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Convert a Rodrigues rotation vector to a 3x3 rotation matrix.\n",
        "\n",
        "        Args:\n",
        "            rvec: Rotation vector (3x1 or 1x3), Rodrigues representation.\n",
        "\n",
        "        Returns:\n",
        "            R: Rotation matrix (3x3).\n",
        "        \"\"\"\n",
        "        R, _ = cv.Rodrigues(rvec)\n",
        "        return R\n",
        "\n",
        "    @staticmethod\n",
        "    def camera_center_in_board(rvec: np.ndarray, tvec: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Compute the camera center in the chessboard/world coordinate system.\n",
        "\n",
        "        Uses the standard pinhole model:\n",
        "            X_c = R * X_w + t\n",
        "        → invert to get camera center in world coords:\n",
        "            C_w = -R^T * t\n",
        "\n",
        "        Args:\n",
        "            rvec: Rotation vector (Rodrigues, 3x1).\n",
        "            tvec: Translation vector (3x1).\n",
        "\n",
        "        Returns:\n",
        "            Camera center in board/world frame as a flat NumPy array (3,).\n",
        "        \"\"\"\n",
        "        R = Cam.rodrigues_to_R(rvec)\n",
        "        C = -R.T @ tvec.reshape(3, 1)\n",
        "        return C.flatten()\n",
        "\n",
        "    @staticmethod\n",
        "    def to_jsonable(mat: np.ndarray) -> List[List[float]]:\n",
        "        \"\"\"\n",
        "        Convert a NumPy matrix/array to a plain Python list-of-lists.\n",
        "\n",
        "        Useful for JSON serialization of calibration matrices.\n",
        "\n",
        "        Args:\n",
        "            mat: NumPy array.\n",
        "\n",
        "        Returns:\n",
        "            Nested lists of floats.\n",
        "        \"\"\"\n",
        "        return mat.tolist()\n"
      ],
      "metadata": {
        "id": "Ybb6Ru9Nb1qL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calibration class"
      ],
      "metadata": {
        "id": "e22R7Expb4yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Calib:\n",
        "    \"\"\"\n",
        "    Camera calibration pipeline utilities:\n",
        "      1) Corner detection on a set of chessboard images\n",
        "      2) Calibration (intrinsics + distortion) from detections\n",
        "      3) Pose estimation per image (rvec/tvec)\n",
        "      4) Serialization helpers\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_corners(image_paths: List[str], pattern_size: Tuple[int, int]):\n",
        "        \"\"\"\n",
        "        Detect inner-corner points for a chessboard across multiple images.\n",
        "\n",
        "        Args:\n",
        "            image_paths: List of image file paths.\n",
        "            pattern_size: (cols, rows) of inner corners (NOT squares).\n",
        "\n",
        "        Returns:\n",
        "            objpoints:   List of (N,3) float32 arrays of object points (Z=0 plane) per image,\n",
        "                         generated in \"unit squares\" (square_size = 1.0). Units are scaled later.\n",
        "            imgpoints:   List of (N,1,2) float32 arrays of detected corner positions per image.\n",
        "            img_size:    (width, height) tuple inferred from the first valid image.\n",
        "\n",
        "        Notes:\n",
        "            - Uses cv.findChessboardCorners + cv.cornerSubPix refinement.\n",
        "            - If a board is not found in an image, that image is skipped.\n",
        "        \"\"\"\n",
        "        objp_unit = Board.object_points(pattern_size, square_size_m=1.0)  # unit grid; scaled later\n",
        "        objpoints, imgpoints = [], []\n",
        "        img_size = None\n",
        "\n",
        "        for p in image_paths:\n",
        "            bgr = cv.imread(p, cv.IMREAD_COLOR)\n",
        "            if bgr is None:\n",
        "                print(f\"[WARN] Could not read image: {p}\")\n",
        "                continue\n",
        "\n",
        "            gray = cv.cvtColor(bgr, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Cache image size (width, height) from the first readable frame\n",
        "            if img_size is None:\n",
        "                img_size = (gray.shape[1], gray.shape[0])\n",
        "\n",
        "            # Robust flags for various lighting conditions\n",
        "            ret, corners = cv.findChessboardCorners(\n",
        "                gray,\n",
        "                pattern_size,\n",
        "                flags=cv.CALIB_CB_ADAPTIVE_THRESH + cv.CALIB_CB_NORMALIZE_IMAGE\n",
        "            )\n",
        "\n",
        "            if ret:\n",
        "                # Sub-pixel refinement for higher accuracy (essential for calibration quality)\n",
        "                corners_ref = cv.cornerSubPix(\n",
        "                    gray,\n",
        "                    corners,\n",
        "                    winSize=(11, 11),\n",
        "                    zeroZone=(-1, -1),\n",
        "                    criteria=(cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "                )\n",
        "                objpoints.append(objp_unit.copy())  # (N,3) float32\n",
        "                imgpoints.append(corners_ref)       # (N,1,2) float32\n",
        "            else:\n",
        "                print(f\"[INFO] Chessboard not found: {os.path.basename(p)}\")\n",
        "\n",
        "        return objpoints, imgpoints, img_size\n",
        "\n",
        "    @staticmethod\n",
        "    def calibrate(objpoints_unit, imgpoints, img_size, square_size_m: float):\n",
        "        \"\"\"\n",
        "        Calibrate camera intrinsics and distortion from corner detections.\n",
        "\n",
        "        Args:\n",
        "            objpoints_unit: List of (N,3) arrays in \"unit\" board scale (square_size=1.0).\n",
        "            imgpoints:      List of (N,1,2) arrays of detected pixel corners.\n",
        "            img_size:       (width, height) image size tuple.\n",
        "            square_size_m:  Real-world square size to scale object points (meters or chosen unit).\n",
        "\n",
        "        Returns:\n",
        "            Dict with:\n",
        "              - \"rms_reprojection_error\": float\n",
        "              - \"K\": 3x3 camera intrinsics matrix (float64)\n",
        "              - \"D\": distortion coefficients (OpenCV format, typically k1..k6, p1, p2, s1..s4 depending on flags)\n",
        "              - \"rvecs\": list of rotation vectors per image (Rodrigues, 3x1)\n",
        "              - \"tvecs\": list of translation vectors per image (3x1)\n",
        "              - \"image_size\": (width, height)\n",
        "\n",
        "        Notes:\n",
        "            - Uses cv.CALIB_RATIONAL_MODEL to estimate higher-order radial terms (k4-k6).\n",
        "            - If no detections are present or img_size is missing, raises ValueError.\n",
        "        \"\"\"\n",
        "        if img_size is None or len(objpoints_unit) == 0:\n",
        "            raise ValueError(\"No valid detections or unknown image size.\")\n",
        "\n",
        "        # Convert unit grid to real-world coordinates\n",
        "        scaled_objpoints = [op * square_size_m for op in objpoints_unit]\n",
        "\n",
        "        ret, K, D, rvecs, tvecs = cv.calibrateCamera(\n",
        "            scaled_objpoints,\n",
        "            imgpoints,\n",
        "            img_size,     # (width, height)\n",
        "            cameraMatrix=None,\n",
        "            distCoeffs=None,\n",
        "            flags=cv.CALIB_RATIONAL_MODEL\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"rms_reprojection_error\": float(ret),\n",
        "            \"K\": K,\n",
        "            \"D\": D,\n",
        "            \"rvecs\": rvecs,\n",
        "            \"tvecs\": tvecs,\n",
        "            \"image_size\": img_size\n",
        "        }\n",
        "\n",
        "    def undistort_preview(\n",
        "        rgb: np.ndarray,\n",
        "        K: np.ndarray,\n",
        "        D: np.ndarray,\n",
        "        calib_size: tuple[int, int] | None = None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Make a side-by-side style preview for UI: (before_rgb, after_rgb).\n",
        "\n",
        "        Args:\n",
        "            rgb:        Input RGB image (H, W, 3), dtype=uint8.\n",
        "            K:          Intrinsic matrix from calibration.\n",
        "            D:          Distortion coefficients from calibration.\n",
        "            calib_size: Optional calibration size (width, height) if rectification maps\n",
        "                        were computed at a specific size; if provided, pass through.\n",
        "\n",
        "        Returns:\n",
        "            Tuple (before_rgb, after_rgb).\n",
        "\n",
        "        Note:\n",
        "            - This uses an external helper `undistort_single_after(...)` which must be\n",
        "              defined elsewhere in your codebase. It should return the undistorted RGB.\n",
        "        \"\"\"\n",
        "        after = undistort_single_after(rgb, K, D, calib_size=calib_size)  # defined elsewhere\n",
        "        return rgb, after\n",
        "\n",
        "    @staticmethod\n",
        "    def save_calibration_json(path: str, calib: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Serialize calibration results to a JSON file.\n",
        "\n",
        "        The matrices/vectors are converted to plain lists for JSON compatibility.\n",
        "\n",
        "        JSON fields:\n",
        "            - rms_reprojection_error: float\n",
        "            - K: 3x3 list-of-lists\n",
        "            - D: list of distortion coefficients\n",
        "            - rvecs: list of [3] (flattened)\n",
        "            - tvecs: list of [3] (flattened)\n",
        "            - image_width, image_height: ints\n",
        "        \"\"\"\n",
        "        out = {\n",
        "            \"rms_reprojection_error\": calib[\"rms_reprojection_error\"],\n",
        "            \"K\": Cam.to_jsonable(calib[\"K\"]),\n",
        "            \"D\": Cam.to_jsonable(calib[\"D\"]),\n",
        "            \"rvecs\": [rv.flatten().tolist() for rv in calib[\"rvecs\"]],\n",
        "            \"tvecs\": [tv.flatten().tolist() for tv in calib[\"tvecs\"]],\n",
        "            \"image_width\": int(calib[\"image_size\"][0]),\n",
        "            \"image_height\": int(calib[\"image_size\"][1]),\n",
        "        }\n",
        "        IO.save_json(out, path)\n",
        "\n",
        "    @staticmethod\n",
        "    def estimate_poses(image_paths, pattern_size, square_size_m, K, D, imgpoints):\n",
        "        \"\"\"\n",
        "        Estimate camera pose (rvec, tvec) for each image where corners were detected.\n",
        "\n",
        "        Args:\n",
        "            image_paths:   List of image paths (aligned with imgpoints order).\n",
        "            pattern_size:  (cols, rows) of inner corners.\n",
        "            square_size_m: Real-world square size.\n",
        "            K:             Intrinsic matrix (3x3).\n",
        "            D:             Distortion coefficients.\n",
        "            imgpoints:     List of (N,1,2) detected corners per image.\n",
        "\n",
        "        Returns:\n",
        "            List of tuples: (image_path, rvec, tvec) for each successful solvePnP.\n",
        "\n",
        "        Notes:\n",
        "            - Uses cv.solvePnP with SOLVEPNP_ITERATIVE (EPnP + Gauss-Newton refinements).\n",
        "            - Assumes object point ordering matches findChessboardCorners corner ordering.\n",
        "        \"\"\"\n",
        "        objp = Board.object_points(pattern_size, square_size_m)\n",
        "        results = []\n",
        "        for pth, corners in zip(image_paths, imgpoints):\n",
        "            ok, rvec, tvec = cv.solvePnP(\n",
        "                objp, corners, K, D, flags=cv.SOLVEPNP_ITERATIVE\n",
        "            )\n",
        "            if ok:\n",
        "                results.append((pth, rvec, tvec))\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "81EZ0ngjb4Nw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pose plot (3D) helper + full pipeline function"
      ],
      "metadata": {
        "id": "knrpczsvcAqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_camera_poses_3d(\n",
        "    pose_list: List[Tuple[str, np.ndarray, np.ndarray]],\n",
        "    square_size_m: float\n",
        "):\n",
        "    \"\"\"\n",
        "    Visualize estimated camera centers in the chessboard/world frame.\n",
        "\n",
        "    Args:\n",
        "        pose_list: List of (image_path, rvec, tvec) for each image with a solved pose.\n",
        "                   rvec/tvec express the camera pose w.r.t. the board (world) frame.\n",
        "        square_size_m: Real-world size of one chessboard square (for axis/grid scaling).\n",
        "\n",
        "    Returns:\n",
        "        Plotly Figure with:\n",
        "          - A faint board grid lying on Z=0 (world XY plane)\n",
        "          - Camera centers as markers labeled #0, #1, …\n",
        "          - Board axes (X, Y, Z) drawn at the origin\n",
        "\n",
        "    Notes:\n",
        "        - World frame convention (from earlier):\n",
        "            Board lies in Z=0; units are meters if `square_size_m` is in meters.\n",
        "        - Camera center is computed as C_w = -R^T * t (already done upstream).\n",
        "    \"\"\"\n",
        "    fig = go.Figure()\n",
        "    if len(pose_list) == 0:\n",
        "        # Nothing to plot → keep consistent aspect mode so axes don't distort\n",
        "        fig.update_layout(title=\"No poses to display\", scene_aspectmode='data')\n",
        "        return fig\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Camera centers\n",
        "    centers, labels = [], []\n",
        "    for pth, rvec, tvec in pose_list:\n",
        "        C = Cam.camera_center_in_board(rvec, tvec)   # shape (3,)\n",
        "        centers.append(C)                            # keep as array/list; we'll cast below\n",
        "        labels.append(os.path.basename(pth))\n",
        "\n",
        "    # Cast to NumPy BEFORE any [:, ...] indexing\n",
        "    centers = np.asarray(centers, dtype=float)       # shape (N, 3)\n",
        "\n",
        "    # Flip Z so cameras in front of the board appear at +Z (matches overlay)\n",
        "    centers[:, 2] *= -1\n",
        "\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=centers[:, 0], y=centers[:, 1], z=centers[:, 2],\n",
        "        mode=\"markers+text\",\n",
        "        text=[f\"#{i}\" for i in range(len(labels))],\n",
        "        textposition=\"top center\",\n",
        "        marker=dict(size=4), name=\"Camera centers\"\n",
        "    ))\n",
        "\n",
        "    # --- Board axes drawn at the origin (0,0,0) ---\n",
        "    L = 3.0 * square_size_m  # axis length in world units\n",
        "    axes = {\n",
        "        \"X\": [[0, L], [0, 0], [0, 0]],\n",
        "        \"Y\": [[0, 0], [0, L], [0, 0]],\n",
        "        \"Z\": [[0, 0], [0, 0], [0, L]],\n",
        "    }\n",
        "    for name, (ax, ay, az) in axes.items():\n",
        "        fig.add_trace(go.Scatter3d(x=ax, y=ay, z=az, mode=\"lines\", name=f\"{name}-axis\"))\n",
        "\n",
        "    # Keep aspect ratio true to data scale; label axes with units\n",
        "    fig.update_layout(\n",
        "        title=\"Estimated Camera Poses w.r.t. Chessboard\",\n",
        "        scene=dict(\n",
        "            xaxis_title=\"X (m)\", yaxis_title=\"Y (m)\", zaxis_title=\"Z (m)\",\n",
        "            aspectmode=\"data\"\n",
        "        ),\n",
        "        legend=dict(x=0, y=1.0)\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "def run_full_calibration(\n",
        "    image_dir: str,\n",
        "    pattern_cols: int,\n",
        "    pattern_rows: int,\n",
        "    square_size_m: float,\n",
        "    max_overlay_images: int = 8,\n",
        "    save_json_path: str = os.path.join(BASE_DIR, \"calibration.json\")\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    End-to-end calibration driver:\n",
        "      - Load images\n",
        "      - Detect chessboard corners\n",
        "      - Calibrate (K, D)\n",
        "      - Estimate per-image poses\n",
        "      - Produce overlay visuals, an undistort preview, and a 3D pose plot\n",
        "      - Save results as JSON\n",
        "\n",
        "    Args:\n",
        "        image_dir: Directory containing calibration images.\n",
        "        pattern_cols: Number of inner corners per row (columns).\n",
        "        pattern_rows: Number of inner corners per column (rows).\n",
        "        square_size_m: Real-world size of each square's side (meters or chosen unit).\n",
        "        max_overlay_images: Max random examples to render with drawn axes.\n",
        "        save_json_path: Output JSON path for calibration results.\n",
        "\n",
        "    Returns:\n",
        "        Dict containing:\n",
        "            - \"json_path\": path to saved calibration JSON\n",
        "            - \"rms\": RMS reprojection error\n",
        "            - \"K\": intrinsics matrix (3x3)\n",
        "            - \"D\": distortion coefficients\n",
        "            - \"image_size\": (width, height)\n",
        "            - \"num_images\": total images found\n",
        "            - \"num_used\": images with valid detections\n",
        "            - \"overlay_images\": list of RGB images with axes drawn\n",
        "            - \"undist_before\": sample RGB before undistortion (or None)\n",
        "            - \"undist_after\": sample RGB after undistortion (or None)\n",
        "            - \"pose_fig\": Plotly Figure with camera centers and axes\n",
        "\n",
        "    Raises:\n",
        "        RuntimeError: if no images are found or if too few detections are available.\n",
        "        ValueError:   propagated from calibration if image size/detections are invalid.\n",
        "\n",
        "    Notes:\n",
        "        - Requires `undistort_single_after(...)` used by `Calib.undistort_preview` to be\n",
        "          defined elsewhere (should return an undistorted RGB).\n",
        "        - Heuristic: requires at least 8 successful board detections for a stable solve.\n",
        "    \"\"\"\n",
        "    pattern_size = Board.pattern_tuple(pattern_cols, pattern_rows)\n",
        "\n",
        "    # Gather input images; fail early if none present\n",
        "    image_paths = IO.list_images(image_dir)\n",
        "    if len(image_paths) == 0:\n",
        "        raise RuntimeError(f\"No images found in {image_dir}. Upload .jpeg files first.\")\n",
        "\n",
        "    # Detect corners across the dataset\n",
        "    objpoints_unit, imgpoints, img_size = Calib.detect_corners(image_paths, pattern_size)\n",
        "    if len(imgpoints) < 8:\n",
        "        raise RuntimeError(f\"Not enough valid detections: {len(imgpoints)} found; need ≥ 8.\")\n",
        "\n",
        "    # Calibrate intrinsics + distortion\n",
        "    calib = Calib.calibrate(objpoints_unit, imgpoints, img_size, square_size_m)\n",
        "\n",
        "    # Persist results\n",
        "    Calib.save_calibration_json(save_json_path, calib)\n",
        "\n",
        "    # Estimate per-image poses using the found corners\n",
        "    K, D = calib[\"K\"], calib[\"D\"]\n",
        "    pose_list = Calib.estimate_poses(image_paths, pattern_size, square_size_m, K, D, imgpoints)\n",
        "\n",
        "    # --- Create sample axis overlays on random subset of images ---\n",
        "    idxs = list(range(len(pose_list)))\n",
        "    random.shuffle(idxs)\n",
        "    idxs = idxs[:max_overlay_images]\n",
        "    overlay_images = []\n",
        "    for i in idxs:\n",
        "        pth, rvec, tvec = pose_list[i]\n",
        "        rgb = IO.imread_rgb(pth)\n",
        "        img_axes = Img.draw_axes(rgb, K, D, rvec, tvec, axis_len=3.0 * square_size_m)\n",
        "        overlay_images.append(Img.put_text(img_axes, f\"axes: {os.path.basename(pth)}\", (10, 30)))\n",
        "\n",
        "    # --- Undistortion preview on the first successful image (if any) ---\n",
        "    undist_before = undist_after = None\n",
        "    if len(pose_list) > 0:\n",
        "        p0, _, _ = pose_list[0]\n",
        "        img0 = IO.imread_rgb(p0)\n",
        "        # calib[\"image_size\"] is (width, height) in this pipeline\n",
        "        undist_before, undist_after = Calib.undistort_preview(\n",
        "            img0, K, D, calib_size=tuple(calib[\"image_size\"])\n",
        "        )\n",
        "\n",
        "    # 3D plot of camera centers + board axes\n",
        "    fig = plot_camera_poses_3d(pose_list, square_size_m)\n",
        "\n",
        "    return {\n",
        "        \"json_path\": save_json_path,\n",
        "        \"rms\": calib[\"rms_reprojection_error\"],\n",
        "        \"K\": calib[\"K\"],\n",
        "        \"D\": calib[\"D\"],\n",
        "        \"image_size\": calib[\"image_size\"],\n",
        "        \"num_images\": len(image_paths),\n",
        "        \"num_used\": len(imgpoints),\n",
        "        \"overlay_images\": overlay_images,\n",
        "        \"undist_before\": undist_before,\n",
        "        \"undist_after\": undist_after,\n",
        "        \"pose_fig\": fig\n",
        "    }\n"
      ],
      "metadata": {
        "id": "eP5K9g5McA5a"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions to save images to files"
      ],
      "metadata": {
        "id": "fT0OIxqqjrXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory for UI images\n",
        "EXPORT_DIR = os.path.join(BASE_DIR, \"exports\")\n",
        "IO.ensure_dir(EXPORT_DIR)\n",
        "\n",
        "def _to_file_list(images, prefix=\"overlay\"):\n",
        "    \"\"\"\n",
        "    Save a list of RGB numpy images to PNG files and return their paths.\n",
        "    \"\"\"\n",
        "    paths = []\n",
        "    for i, img in enumerate(images):\n",
        "        fp = os.path.join(EXPORT_DIR, f\"{prefix}_{i:02d}.png\")\n",
        "        IO.imwrite_rgb(fp, img)  # writes RGB -> PNG\n",
        "        paths.append(fp)\n",
        "    return paths\n",
        "\n",
        "EXPORT_ROOT = os.path.join(BASE_DIR, \"exports\")\n",
        "IO.ensure_dir(EXPORT_ROOT)\n",
        "\n",
        "def _save_gallery_images_np(images, prefix=\"overlay\", max_side=1600):\n",
        "    \"\"\"\n",
        "    Accepts a list of RGB uint8 numpy arrays and returns a list of fresh, unique PNG file paths.\n",
        "    Resizes if images are very large to avoid Colab/Gradio rendering issues.\n",
        "    \"\"\"\n",
        "    # Create a unique “session” folder each run to dodge caching/collisions\n",
        "    session_dir = os.path.join(EXPORT_ROOT, f\"{prefix}_{int(time.time())}_{uuid.uuid4().hex[:6]}\")\n",
        "    IO.ensure_dir(session_dir)\n",
        "\n",
        "    paths = []\n",
        "    for i, arr in enumerate(images):\n",
        "        if arr is None:\n",
        "            continue\n",
        "        # Ensure uint8 RGB\n",
        "        if arr.dtype != np.uint8:\n",
        "            arr = np.clip(arr, 0, 255).astype(np.uint8)\n",
        "        if arr.ndim == 2:\n",
        "            arr = np.stack([arr]*3, axis=-1)\n",
        "        if arr.shape[2] == 4:  # RGBA -> RGB\n",
        "            arr = arr[..., :3]\n",
        "\n",
        "        im = Image.fromarray(arr, mode=\"RGB\")\n",
        "        # Downscale large images for more reliable display\n",
        "        w, h = im.size\n",
        "        scale = min(1.0, max_side / max(w, h))\n",
        "        if scale < 1.0:\n",
        "            im = im.resize((int(w*scale), int(h*scale)), Image.LANCZOS)\n",
        "\n",
        "        fp = os.path.join(session_dir, f\"{prefix}_{i:02d}.png\")\n",
        "        im.save(fp, format=\"PNG\", optimize=True)\n",
        "        paths.append(fp)\n",
        "    return paths\n",
        "\n",
        "def _to_rgb_uint8(img: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Return a contiguous RGB uint8 HxWx3 image (downscale if huge).\"\"\"\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    arr = img\n",
        "    # Ensure uint8 range\n",
        "    if arr.dtype != np.uint8:\n",
        "        arr = np.clip(arr, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Expand gray to RGB\n",
        "    if arr.ndim == 2:\n",
        "        arr = np.stack([arr]*3, axis=-1)\n",
        "\n",
        "    # Drop alpha if present\n",
        "    if arr.ndim == 3 and arr.shape[2] == 4:\n",
        "        arr = arr[:, :, :3]\n",
        "\n",
        "    # Sometimes arrays come in BGR; our pipeline produces RGB, but to be safe:\n",
        "    # If you KNOW an array is BGR, uncomment:\n",
        "    # arr = cv.cvtColor(arr, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    # Downscale very large images for Colab stability\n",
        "    h, w = arr.shape[:2]\n",
        "    max_side = 1200\n",
        "    scale = min(1.0, max_side / float(max(h, w)))\n",
        "    if scale < 1.0:\n",
        "        arr = cv.resize(arr, (int(round(w*scale)), int(round(h*scale))), interpolation=cv.INTER_AREA)\n",
        "\n",
        "    # Make sure memory is contiguous; Gradio can be picky here\n",
        "    arr = np.ascontiguousarray(arr)\n",
        "    return arr\n",
        "\n",
        "def _to_pil_rgb(img_np, max_side=1200):\n",
        "    if img_np is None or img_np.size == 0:\n",
        "        return None\n",
        "    if img_np.ndim < 2:\n",
        "        return None\n",
        "    arr = img_np\n",
        "    if arr.dtype != np.uint8:\n",
        "        arr = np.clip(arr, 0, 255).astype(np.uint8)\n",
        "    if arr.ndim == 2:\n",
        "        arr = np.stack([arr]*3, axis=-1)\n",
        "    if arr.ndim == 3 and arr.shape[2] == 4:\n",
        "        arr = arr[:, :, :3]\n",
        "    h, w = arr.shape[:2]\n",
        "    if h == 0 or w == 0:\n",
        "        return None\n",
        "    scale = min(1.0, max_side / float(max(h, w)))\n",
        "    if scale < 1.0:\n",
        "        nh, nw = int(round(h*scale)), int(round(w*scale))\n",
        "        if nh > 0 and nw > 0:\n",
        "            arr = cv.resize(arr, (nw, nh), interpolation=cv.INTER_AREA)\n",
        "    return Image.fromarray(arr, mode=\"RGB\")\n",
        "\n",
        "\n",
        "def _prep_gallery_pil(images_list):\n",
        "    out = []\n",
        "    for im in images_list or []:\n",
        "        pi = _to_pil_rgb(im)\n",
        "        if pi is not None:          # skip empties\n",
        "            out.append(pi)\n",
        "    return out\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def _pil_to_base64(img: Image.Image) -> str:\n",
        "    buf = io.BytesIO()\n",
        "    img.save(buf, format=\"PNG\")\n",
        "    return base64.b64encode(buf.getvalue()).decode(\"ascii\")\n",
        "\n",
        "def _imgs_to_html(pils, captions=None, max_w=380):\n",
        "    if not pils:\n",
        "        return \"<div style='color:#bbb'>No images to display.</div>\"\n",
        "    cards = []\n",
        "    for i, im in enumerate(pils):\n",
        "        b64 = _pil_to_base64(im)\n",
        "        cap = (captions[i] if captions and i < len(captions) else \"\")\n",
        "        cards.append(\n",
        "            f\"\"\"\n",
        "            <div style=\"display:flex;flex-direction:column;align-items:center;margin:8px;\">\n",
        "              <img src=\"data:image/png;base64,{b64}\" style=\"max-width:{max_w}px;height:auto;border:1px solid #444;border-radius:6px;\" />\n",
        "              <div style=\"color:#ccc;font-size:12px;margin-top:4px\">{cap}</div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        )\n",
        "    return f\"<div style='display:flex;flex-wrap:wrap;'>{''.join(cards)}</div>\""
      ],
      "metadata": {
        "id": "gC-WbO4Fjqzb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function for undistortion"
      ],
      "metadata": {
        "id": "jLoxcPUL7dz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def undistort_single_after(rgb: np.ndarray, K: np.ndarray, D: np.ndarray,\n",
        "                           calib_size: tuple[int, int] | None = None) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Return just the undistorted image (RGB, uint8) for one input frame.\n",
        "\n",
        "    rgb         : HxWx3, RGB, uint8\n",
        "    K, D        : intrinsics and distortion from calibration (float64 recommended)\n",
        "    calib_size  : (calib_width, calib_height) from calibration. If present and the\n",
        "                  input image size differs, K is scaled accordingly.\n",
        "    \"\"\"\n",
        "    assert rgb.ndim == 3 and rgb.shape[2] == 3, \"rgb must be HxWx3 RGB\"\n",
        "    h, w = rgb.shape[:2]\n",
        "\n",
        "    # Ensure expected types/shapes for OpenCV\n",
        "    K = np.asarray(K, dtype=np.float64).copy()\n",
        "    D = np.asarray(D, dtype=np.float64).reshape(-1)\n",
        "\n",
        "    # If current image size != calibration size, scale K\n",
        "    if calib_size is not None:\n",
        "        cw, ch = calib_size  # width, height from calibration\n",
        "        if (w, h) != (cw, ch):\n",
        "            sx, sy = w / float(cw), h / float(ch)\n",
        "            K[0, 0] *= sx       # fx\n",
        "            K[0, 2] *= sx       # cx\n",
        "            K[1, 1] *= sy       # fy\n",
        "            K[1, 2] *= sy       # cy\n",
        "\n",
        "    # Build rectification map and remap (more stable than single-call undistort)\n",
        "    newK, _ = cv.getOptimalNewCameraMatrix(\n",
        "        K, D, (w, h), alpha=0.5, centerPrincipalPoint=True\n",
        "    )\n",
        "    map1, map2 = cv.initUndistortRectifyMap(K, D, None, newK, (w, h), cv.CV_16SC2)\n",
        "\n",
        "    bgr_in  = cv.cvtColor(rgb, cv.COLOR_RGB2BGR)\n",
        "    bgr_out = cv.remap(bgr_in, map1, map2, interpolation=cv.INTER_LINEAR,\n",
        "                       borderMode=cv.BORDER_CONSTANT)\n",
        "    return cv.cvtColor(bgr_out, cv.COLOR_BGR2RGB)\n"
      ],
      "metadata": {
        "id": "nulLqIQEkW1d"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Gradio Inline UI"
      ],
      "metadata": {
        "id": "SYjU7pbkfvA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Simple app-level state (paths shared across callbacks) ---\n",
        "STATE = {\n",
        "    \"image_dir\": IMG_DIR,\n",
        "    \"last_calib_json\": os.path.join(BASE_DIR, \"calibration.json\")\n",
        "}\n",
        "\n",
        "\n",
        "def ui_save_uploads(files):\n",
        "    \"\"\"\n",
        "    Save uploaded images into STATE['image_dir'] and return a status line + list of paths.\n",
        "\n",
        "    Args:\n",
        "        files: List of file-like objects from gr.Files() (Gradio temp files). Each f has .name\n",
        "\n",
        "    Returns:\n",
        "        (status_markdown: str, image_paths_json: list[str])\n",
        "    \"\"\"\n",
        "    IO.ensure_dir(STATE[\"image_dir\"])\n",
        "    saved = 0\n",
        "    paths = []\n",
        "\n",
        "    # Gradio passes None/[] when nothing selected\n",
        "    if not files:\n",
        "        return \"No files uploaded.\", []\n",
        "\n",
        "    for f in files:\n",
        "        # Use original filename (basename) and copy from Gradio's temp file path\n",
        "        fname = os.path.basename(f.name)\n",
        "        dst = os.path.join(STATE[\"image_dir\"], fname)\n",
        "        # NOTE: This overwrites silently if filenames collide; acceptable for quick demos.\n",
        "        # If you want to avoid collisions, consider prefixing with uuid4.\n",
        "        with open(f.name, \"rb\") as src, open(dst, \"wb\") as out:\n",
        "            out.write(src.read())\n",
        "        saved += 1\n",
        "        paths.append(dst)\n",
        "\n",
        "    # Return a friendly status and the **current** directory listing (sorted)\n",
        "    return f\"Saved {saved} image(s) to {STATE['image_dir']}\", IO.list_images(STATE[\"image_dir\"])\n",
        "\n",
        "\n",
        "def ui_run_calibration(pattern_cols, pattern_rows, square_size_m, max_overlay):\n",
        "    \"\"\"\n",
        "    Run calibration and prepare UI outputs (text, 3D plot, overlays HTML, undistort HTML).\n",
        "\n",
        "    Args:\n",
        "        pattern_cols: Inner-corner columns (int-like; gr.Number -> float, cast below)\n",
        "        pattern_rows: Inner-corner rows (int-like; gr.Number -> float, cast below)\n",
        "        square_size_m: Square side length in meters (float)\n",
        "        max_overlay: Max number of overlay images to render (int)\n",
        "\n",
        "    Returns:\n",
        "        Tuple:\n",
        "          - info_markdown (str)\n",
        "          - pose_fig (plotly.Figure)\n",
        "          - overlay_html (str)\n",
        "          - undist_html (str)\n",
        "\n",
        "    Notes:\n",
        "        - Depends on helpers: _prep_gallery_pil, _imgs_to_html, _to_pil_rgb\n",
        "        - Also uses Calib.undistort_preview which calls `undistort_single_after(...)` (defined elsewhere).\n",
        "        - Keeps output TYPES identical on success and on error (important for Gradio wiring).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = run_full_calibration(\n",
        "            image_dir=STATE[\"image_dir\"],\n",
        "            pattern_cols=int(pattern_cols),\n",
        "            pattern_rows=int(pattern_rows),\n",
        "            square_size_m=float(square_size_m),\n",
        "            max_overlay_images=int(max_overlay),\n",
        "            save_json_path=STATE[\"last_calib_json\"],\n",
        "        )\n",
        "\n",
        "        # Summary block for the UI (markdown)\n",
        "        info = (\n",
        "            f\"✅ Calibration completed\\n\"\n",
        "            f\"• RMS reprojection error: {result['rms']:.4f}\\n\"\n",
        "            f\"• Images in folder: {result['num_images']}\\n\"\n",
        "            f\"• Used with valid corners: {result['num_used']}\\n\"\n",
        "            f\"• Image size: {result['image_size'][0]} x {result['image_size'][1]}\\n\"\n",
        "            f\"• Saved: {result['json_path']}\"\n",
        "        )\n",
        "\n",
        "        # ------- overlays -> HTML gallery -------\n",
        "        # result['overlay_images'] is a list of RGB np.ndarrays\n",
        "        overlay_pil = _prep_gallery_pil(result[\"overlay_images\"])  # expects list[PIL.Image]\n",
        "        overlay_caps = [f\"axes {i+1}\" for i in range(len(overlay_pil))]  # align captions with produced overlays\n",
        "        overlay_html_str = _imgs_to_html(overlay_pil, captions=overlay_caps, max_w=360)\n",
        "\n",
        "        # ------- undistortion (2 panels) -> HTML -------\n",
        "        undist_html_str = \"<div style='color:#bbb'>No undistortion preview.</div>\"\n",
        "        if result[\"undist_before\"] is not None:\n",
        "            before_np = result[\"undist_before\"]\n",
        "            after_np  = result[\"undist_after\"]\n",
        "\n",
        "            # Convert to PIL for consistent HTML gallery rendering\n",
        "            before_pil = _to_pil_rgb(before_np)\n",
        "            after_pil  = _to_pil_rgb(after_np)\n",
        "\n",
        "            # Be defensive: if \"after\" failed, mirror \"before\" so UI still shows 2 images\n",
        "            if after_pil is None:\n",
        "                after_pil = before_pil\n",
        "\n",
        "            if before_pil is None:\n",
        "                undist_html_str = \"<div style='color:#f88'>Undistortion preview unavailable.</div>\"\n",
        "            else:\n",
        "                undist_html_str = _imgs_to_html([before_pil, after_pil],\n",
        "                                                captions=[\"Before\", \"After\"], max_w=480)\n",
        "\n",
        "        # pose_fig is a Plotly figure created by plot_camera_poses_3d (works with gr.Plot)\n",
        "        return info, result[\"pose_fig\"], overlay_html_str, undist_html_str\n",
        "\n",
        "    except Exception as e:\n",
        "        # Keep outputs the same types as on success to avoid UI wiring errors\n",
        "        err = f\"❌ {type(e).__name__}: {e}\"\n",
        "        return (\n",
        "            err,\n",
        "            go.Figure(),  # empty figure\n",
        "            f\"<div style='color:#f88'>{err}</div>\",\n",
        "            f\"<div style='color:#f88'>{err}</div>\"\n",
        "        )\n",
        "\n",
        "\n",
        "# --- Gradio UI layout ---\n",
        "with gr.Blocks(title=\"Camera Calibration (OpenCV + Gradio)\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"# 📷 Camera Calibration — OpenCV + Gradio\\n\"\n",
        "        \"Upload chessboard photos, then run calibration. Results saved to `calibration.json`.\"\n",
        "    )\n",
        "\n",
        "    # ----- Tab 1: Upload -----\n",
        "    with gr.Tab(\"1) Upload Images\"):\n",
        "        # Accept multiple image files; Gradio supplies temporary file objects\n",
        "        files = gr.Files(file_types=[\"image\"], file_count=\"multiple\", label=\"Upload .jpeg images\")\n",
        "        status = gr.Markdown()\n",
        "        # Show the current image paths in /content/images (JSON widget is convenient for lists)\n",
        "        gallery_list = gr.JSON(label=\"Current images in /content/images (paths)\")\n",
        "        save_btn = gr.Button(\"Save to /content/images\")\n",
        "        save_btn.click(fn=ui_save_uploads, inputs=files, outputs=[status, gallery_list])\n",
        "\n",
        "    # ----- Tab 2: Calibrate -----\n",
        "    with gr.Tab(\"2) Calibrate & Visualize\"):\n",
        "        with gr.Row():\n",
        "            # Use integer-like Numbers for pattern; casts happen inside the callback\n",
        "            pattern_cols = gr.Number(value=9, precision=0, label=\"Inner corners (cols)\")\n",
        "            pattern_rows = gr.Number(value=6, precision=0, label=\"Inner corners (rows)\")\n",
        "            # ≈ 21.77 mm (about 6/7 inch) — adjust to your printed board\n",
        "            square_size  = gr.Number(value=0.0217714286, label=\"Square size (meters)\")\n",
        "            max_overlay  = gr.Slider(3, 12, value=8, step=1, label=\"Sample overlays to show\")\n",
        "\n",
        "        run_btn = gr.Button(\"▶️ Run Calibration\")\n",
        "        out_info = gr.Markdown()\n",
        "        pose_fig = gr.Plot(label=\"Camera Poses (3D)\")     # accepts Plotly Figure\n",
        "        overlay_html = gr.HTML(label=\"Detected pattern + world axes\")\n",
        "        undist_html  = gr.HTML(label=\"Undistortion (before/after)\")\n",
        "\n",
        "        # Wire the button to the calibration pipeline\n",
        "        run_btn.click(\n",
        "            fn=ui_run_calibration,\n",
        "            inputs=[pattern_cols, pattern_rows, square_size, max_overlay],\n",
        "            outputs=[out_info, pose_fig, overlay_html, undist_html]\n",
        "        )\n",
        "\n",
        "# Launch inline in Colab; share=False limits to the current session\n",
        "demo.launch(inline=True, share=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "5YOnp2Evfuj3",
        "outputId": "f84e6f65-c3e0-4676-818d-1d283b483b75"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7862, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}